{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# a concise way to implement C-like structures. \n",
    "# ref: https://stackoverflow.com/questions/1878710/struct-objects-in-python\n",
    "config = lambda: 0\n",
    "# note: put a comma after `tf.random_normal` will make it viewed as a tuple cuz it's not dict!...\n",
    "config.weights_initializer = tf.random_normal\n",
    "config.bias_initializer = tf.zeros\n",
    "config.feature_dimension = 2\n",
    "config.num_of_class = 2\n",
    "config.training_epochs = 1000\n",
    "\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.W = tf.Variable(self.config.weights_initializer([\n",
    "            self.config.feature_dimension, \n",
    "            self.config.num_of_class\n",
    "        ]))\n",
    "        self.b = tf.Variable(self.config.bias_initializer(shape=[self.config.num_of_class, ]) + 0.1)\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "    \n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.W_holder = tf.placeholder(tf.float32, [\n",
    "            self.config.feature_dimension,\n",
    "            self.config.num_of_class\n",
    "        ])\n",
    "        self.b_holder = tf.placeholder(tf.float32, [self.config.num_of_class, ])\n",
    "        \n",
    "        self.x_s_holder = tf.placeholder(tf.float32, [None, self.config.feature_dimension])\n",
    "        self.y_s_holder = tf.placeholder(tf.float32, [None, self.config.num_of_class])\n",
    "        self.f_holder = self.logit()\n",
    "        self.f_holder = tf.nn.softmax(self.f_holder)\n",
    "\n",
    "        indices = tf.transpose(tf.convert_to_tensor([\n",
    "            list(range(100)),\n",
    "            tf.argmax(self.y_s_holder, axis=1)\n",
    "        ]))\n",
    "        self.loss_holder = tf.reduce_mean(tf.negative(tf.log(tf.gather_nd(self.f_holder, indices))))\n",
    "#         self.loss_holder = tf.reduce_mean(tf.square(self.f_holder - self.y_s_holder))\n",
    "#         self.loss_holder = tf.reduce_mean(\n",
    "#             tf.nn.softmax_cross_entropy_with_logits(logits=self.f_holder, labels=self.y_s_holder)\n",
    "#         )\n",
    "#         self.loss_holder = tf.reduce_mean(\n",
    "#             -tf.reduce_sum(self.y_s_holder * tf.log(self.f_holder), reduction_indices=[1])\n",
    "#         )\n",
    "\n",
    "        self.acc_holder = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.f_holder, axis=1), tf.argmax(self.y_s_holder, axis=1)), tf.float32))\n",
    "        self.train_op_holder = tf.train.GradientDescentOptimizer(0.1).minimize(self.loss_holder)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.sess.close()\n",
    "    \n",
    "    def fit(self, x_s_train, y_s_train, params_trace_recording=False):\n",
    "        W_trace = [self.sess.run(self.W)]\n",
    "        b_trace = [self.sess.run(self.b)]\n",
    "        \n",
    "        for step in range(self.config.training_epochs):\n",
    "            _, loss, acc = self.sess.run([self.train_op_holder, self.loss_holder, self.acc_holder], feed_dict={\n",
    "                self.x_s_holder: x_s_train,\n",
    "                self.y_s_holder: y_s_train\n",
    "            })\n",
    "        \n",
    "            if params_trace_recording:\n",
    "                W_trace.append(self.sess.run(self.W))\n",
    "                b_trace.append(self.sess.run(self.b))\n",
    "#             if step % 1000 == 0: print(loss, acc)\n",
    "        \n",
    "        print('training completed.')\n",
    "        return W_trace, b_trace\n",
    "    \n",
    "    def logit(self, custom_params=None):\n",
    "        if custom_params:\n",
    "            logit_holder = tf.matmul(self.x_s_holder, self.W_holder) + self.b_holder\n",
    "        else:\n",
    "            logit_holder = tf.matmul(self.x_s_holder, self.W) + self.b\n",
    "        return logit_holder\n",
    "    \n",
    "    # predict is the actual prediction result based the logit.\n",
    "    def predict(self, x_s, custom_params=None):\n",
    "        predict = tf.argmax(self.logit(custom_params), axis=1)\n",
    "        feed_dict = {self.x_s_holder: x_s}\n",
    "        if custom_params:\n",
    "            feed_dict[self.W_holder] = custom_params['W']\n",
    "            feed_dict[self.b_holder] = custom_params['b']\n",
    "        predict = self.sess.run(predict, feed_dict=feed_dict)\n",
    "        return predict\n",
    "        \n",
    "\n",
    "# data preparation.\n",
    "x = np.linspace(-1, 1, 50)\n",
    "y_1 = 0.5 * np.sin(3.1*(x-0.5)) + 0.4\n",
    "y_2 = 0.5 * np.sin(3.1*(x-0.5)) - 0.45\n",
    "\n",
    "x_s_train = np.array(\n",
    "    list(zip(x, y_1)) +\n",
    "    list(zip(x, y_2))\n",
    ")\n",
    "y_s_train = np.array([[1, 0]]*50 + [[0, 1]]*50)\n",
    "\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    # training process of NN.\n",
    "    nn = NN(config)\n",
    "    W_trace, b_trace = nn.fit(x_s_train, y_s_train, params_trace_recording=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
